---
output:
  pdf_document: 
    keep_tex: yes
  html_document: default
---

## Pacote R com as funções de treinamento, execução e visualização de dados

##### importações

```{R}
library(bnlearn)
library(Hmisc)
library(dbnlearn)
library(rbmn)
#source('bnlearn_discrete_multivar_prediction_eval.R')
```

#### 

#### BuildSimulationData

```{r}
BuildSimulationData <- function (nHarvests, nPhases, nAreas = NULL, ...) {
  
  
  areasList <- list()
  if(is.null(nAreas)){
    # por padrão gera-se 6 áreas
    # cada área tem uma relação entre as variáveis e a produção 
    
    areanames = c("Area_1", "Area_2", "Area_3", "Area_4", "Area_5", "Area_6")
    areatype  = c(1,2,3,4,5,6)
    for (i in 1 : length(areanames)){
      areasList[[i]] <- c(areanames =  areanames[i], areatype  = areatype[i])
    }
  }else{
    # se for definido o número de áreas, os tipos são atribuidos aleatóriamente
    for (i in 1 : nAreas){
      tempType = sample(1:6, 1)
      #tempType = 5
      tempName <- paste("Area", i, sep = "_")
      areasList[[i]] = c(areaName = tempName, areatype = tempType)
    }
  }
  
  # definição das variáveis pela funcao defVars 
  defProdVariables = defVars(...)
 
  
  completeSimValues = list()
  namesArea = array(dim = length(areasList))
  
# Para cada área Calcula os valores das variáveis
# e da producao pela função setSimVarValues
  
  for (a in 1:length(areasList)) {
    
    #cat("Calculando valores da área ",a,"\n")

    completeSimValues[[a]] = setSimVarValues(nHarvests, areasList[[a]][2],defProdVariables,nPhases)
    namesArea[a] = paste("Area", a, "type", areasList[[a]][2], sep = "_")
  }
  names(completeSimValues) = namesArea

  # Normalizando (entre 0 e 1) dados da produção 
    # DUVIDA: é a abordagem mais correta. (??)
  #      
  # temp <- array(dim = length(areasList))
  # i=1
  # for(a in 1 : length(areasList)){
  #   for(h in 1 : nHarvests){
  #     temp[i] <- completeSimValues[[a]][[h]][1,length(defProdVariables)+1]
  #     i=1+i
  #   }
  # }
  # 
  # i=1
  # temp <- f_minmax(temp)
  # for(a in 1 : length(areasList)){
  #   for(h in 1 : nHarvests){
  #     completeSimValues[[a]][[h]][,length(defProdVariables)+1] <- temp[i]
  #     i=1+i
  #   }
  # }
  # 
  return (completeSimValues)
  
}
```

#### 

#### defVars

```{r}
# função para geração das variáveis
# chamada no escopo da função BuildSimulationData

defVars <- function (n_var = NULL, type_var = NULL, name_var = NULL){
  prodVariables = list()

  # Se não for definido o número de variáveis o padrão são as 3 abaixo  
  if(is.null(n_var)){
    # Definição das variáveis: nome, valor mínimo, valor máximo, tipo 
    # type (up=1,osc=2,const=3)
    prodVariables[[1]] = c("PrecAcum",0,1,1)
    prodVariables[[2]] = c("Insol",0,1,2)
    prodVariables[[3]] = c("Compact",-1,1,3)

  return (prodVariables)
  }else
    if(!is.null(type_var) | !is.null(name_var)){
      # sendo informado o n de variáveis e o nome e o comportamento delas
      # as variáveis são geradas conforme abaixo:
      if(length(type_var)!= n_var | length(name_var)!= n_var){
        stop("parâmetros incorretos. Se informados, tipos e nomes de variáveis devem ser informados para todas as variáveis")
      }else{
        for (i in 1 : n_var){
        # type (up=1,osc=2,const=3)
          if(type_var[i] == 3){
            prodVariables[[i]] = c(name_var[i], -1, 1, type_var[i])
          }else{
            prodVariables[[i]] = c(name_var[i], 0, 1, type_var[i])
          }
        }
      }
        return (prodVariables)
        }else{
          # Sendo informado o n de variáveis, sem mais detalhes a geração 
          # ocorre de maneira aleatória, conforme abaixo:
          for (i in 1 : n_var){
            tempType = sample(1:3, 1)
            tempName <- paste("x", i, sep = "_" )
            if(tempType == 3){
              prodVariables[[i]] = c(tempName, -1, 1, tempType)
              }else{
                prodVariables[[i]] = c(tempName, 0, 1, tempType)
              }
            }
          return (prodVariables)
        }
}

```

#### 

#### setSimVarValues

```{r}
# Função para geração dos valores das variáveis e das colheitas para cada
# área informada.
#CHAMADA NO ESCOPO DA FUNÇÃO BuildSimulationData()
#A função é chamada uma vez por área

setSimVarValues <- function (harvests, areatype, prodvars, nPhases){
  colheitas <-list()
  names_colheitas <- array(dim = harvests)
  
  # define os nomes das variáveis 
  for(i in 1: harvests){
  # pra cada colheita da área
    # cria uma matriz de 'numero de fases' linhas e
    # 'numero de variáveis' colunas 
    # (sendo a v pridução nvariaveis independente +1)
    # aqui eu usei matrizes pq é mais fácil fazer operações matemáticas 
    # nas matrizes
    fases <- matrix(nrow=nPhases, ncol= length(prodvars)+1)
    colnames(fases) <-  colnames(fases, do.NULL = FALSE, prefix = "variavel_")
    colnames(fases)[length(prodvars)+1] <-  "colheita"
    rownames(fases) <-  rownames(fases, do.NULL = FALSE, prefix = "fase_")
    colheitas[[i]] = fases
    names_colheitas[i] = paste("colheita", i, sep = "_")
  }
  names(colheitas) = names_colheitas
  
  # gera os valores das variáveis independentes
  for (var in 1 : length(prodvars)){# pra cada vaiável 
    for (harv in 1:harvests) {# pra cada colheita
      random_value   = runif(1, 
                             min=as.numeric(prodvars[[var]][2]),
                             max=as.numeric(prodvars[[var]][3]))
      last_value_var = 0
      const_value    = random_value
      for (pha in 1:nPhases){ #pra cada fase
        # type (up=1,osc=2,const=3)
        if (prodvars[[var]][4]==1){
          v_value = random_value + last_value_var
          last_value_var = v_value
        }else
          if (prodvars[[var]][4]==2){
            v_value = random_value
          }else
            if (prodvars[[var]][4]==3){
              v_value = const_value
            }
        
        colheitas[[harv]][pha,var] = v_value
        random_value = runif(1,
                             min=as.numeric(prodvars[[var]][2]), 
                             max=as.numeric(prodvars[[var]][3]))
      }#for pha in 1:nPhases
    }#for harv in 1:harvests
  }#for var in 1 : length(prodvars)

# Normalizando (entre 0 e 1 ou 1- e 1, conforme o tipo de variável) 
# dos dados das variáves antes de calcular os valores de produção  
       # DUVIDA: é a abordagem mais correta. (??)
  
for(h in 1 : harvests){
  for(v in 1 : length(prodvars)){
    if(max(abs(colheitas[[h]][,v])) > 1){
      colheitas[[h]][,v] = f_minmax(colheitas[[h]][,v])
      
      # corrige valores extremos 0 e 1, adicionando/subtraindo
      # um valor aleatório na 3ª casa depois da vírgula
      colheitas[[h]][which.max(colheitas[[h]][,v]),v] = max(colheitas[[h]][,v]) - runif(1)/100
      colheitas[[h]][which.min(colheitas[[h]][,v]),v] = min(colheitas[[h]][,v]) + runif(1)/100
 
     }
  }
}

# calcula o valor da produção com base nas relações arbitradas com as variáveis 
  
       
##### POR DEFAULT CONSIDERA-SE 3 VARIÁVES:
if(length(prodvars)==3){
#  print('AQUI')
 
  # Área 1: o peso de produção varia linearmente com os valores de todas as variáveis 
  # nas duas primeiras fases fenológicas
  # Prod = (X11 + X12 + X21 + X22 + X31 + X32)
  if (areatype == 1) {
    
    for (h in 1: harvests){
      # cada colheita recebe o somatório de cada linha (fase) 
      # length(prodvars) é a quantidade de variáveis independentes
      # lembrando que 'colheitas' é uma lista de matrizes, daí
      # colheitas[[h]][,1:length(prodvars)] é:
        # colheitas[[h]] a matriz da colheita h
        # [,1:length(prodvars)] pra todas as linas da coluna 1 até a penultima
        # a última -- [,length(prodvars)+1] -- é onde fica a var 'colheita'
      colheitas[[h]][,length(prodvars)+1] = sum(colheitas[[h]][,1:length(prodvars)])
    }
  }
   
  # Área 2: o peso de produção varia com o quadrado de X1
  # Prod = (X11^2 + X12^2 + X13^2 + X14^2 + X15^2)
  else if (areatype == 2) { 
    for(h in 1:harvests) {
        colheitas[[h]][,length(prodvars)+1] = sum((colheitas[[h]][,1])^2)
    }
  }
  
  # Área 3: o peso de produção varia com o quadrado de X3
  else if (areatype == 3) {
     for(h in 1:harvests) {
        colheitas[[h]][,length(prodvars)+1] = sum((colheitas[[h]][,3])^2)
    }
  }
  
  # Área 4: o peso de produção é inversamente proporcional à soma de X1 com X3
  # Prod = 1/(X11+X13) + 1/(...)
  else if (areatype == 4) {
    for(h in 1:harvests) {
       producaoPhase = 0
      for(p in 1:nPhases){
        temp = 1/(colheitas[[h]][p,1]+colheitas[[h]][p,3])
         producaoPhase =  producaoPhase + temp
        }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
  
  # Área 5: o peso da produção decresce com uma ponderação dos valores de X2:
  # Prod = 1* X21 + 0,8* X22 + 0,6*X23 + 0,4*X24 + 0,2*X25
  else if (areatype == 5) {
    for(h in 1:harvests) {
       producaoPhase = 0
      chunk = 100/nPhases
      for(p in 1:nPhases){
        temp = (colheitas[[h]][p,2])*(100-(chunk*p-1))/100
         producaoPhase =  producaoPhase + temp
      }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
  
  # Área 6: o peso da produção cresce com uma ponderação dos valores de X1:
  # Prod = 0,2*X11 + 0,4* X12 + 0,6*X13 + 0,8*X14 + 1*X15
  else if (areatype == 6){
    for(h in 1:harvests) {
      producaoPhase = 0
      chunk = 100/nPhases
      for(p in 1:nPhases){
        temp = ((colheitas[[h]][p,1])*(chunk*p))/100
        producaoPhase =  producaoPhase + temp
        }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
}else{# se forem definidas mais de 3 variáveis 

#  print('ALI')
  
  # Área 1: o peso de produção varia linearmente com os valores
  # de todas as variáveis nas duas primeiras fases fenológicas
  # Prod = (X11 + X12 + X21 + X22 + X31 + X32)

  if (areatype == 1) {
    for (h in 1: harvests){
      colheitas[[h]][,length(prodvars)+1] = sum(colheitas[[h]][,1:length(prodvars)])
    }
  }
  
  # Área 2: o peso de produção varia com o quadrado das variáveis impares 
  # Prod = Σ(Xi1^2 + Xi2^2 + Xi3^2 + Xi4^2 + Xi5^2) | i=(2k+1), k(0:infinito)
  else if (areatype == 2) { 
    for(h in 1:harvests) {
        producaoVar = 0
        for (v in 1 : length(prodvars)){
          if(v %% 2 == 0){next}
          temp = sum((colheitas[[h]][,v])^2)
          producaoVar =  producaoVar + temp
        }
        colheitas[[h]][,length(prodvars)+1] = producaoVar
    }
  }
  
  # Área 3: o peso de produção varia com o quadrado das variáveis pares
  # Prod = Σ(Xi1^2 + Xi2^2 + Xi3^2 + Xi4^2 + Xi5^2) | i=(2k), k(0:infinito)
  else if (areatype == 3){
    for(h in 1:harvests) {
      producaoVar = 0
      for (v in 1 : length(prodvars)){
        if(v %% 2 != 0){next}
          temp = sum((colheitas[[h]][,v])^2)
          producaoVar =  producaoVar + temp
        }
        colheitas[[h]][,length(prodvars)+1] = producaoVar
    }
  }
  
  # Área 4: o peso de produção é inversamente proporcional à soma das variáveis impares
  # Prod = 1/(X11+X13) + 1/(...)
  else if (areatype == 4) {
    for(h in 1:harvests) {
       producaoPhase = 0
      for(p in 1:nPhases){
        denominTemp = 0
        for (v in 1 : length(prodvars)){
          if(v %% 2 == 0){next}
          temp = sum(colheitas[[h]][p,v])
          denominTemp =  denominTemp + temp
        }
        temp2 = 1/denominTemp
         producaoPhase =  producaoPhase + temp2
      }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
  
  # Área 5: o peso da produção decresce com uma ponderação da soma das variáveis ímpares 
  # Prod = 1* X21 + 0,8* X22 + 0,6*X23 + 0,4*X24 + 0,2*X25
  else if (areatype == 5) {
    for(h in 1:harvests) {
      for(p in 1:nPhases){
        producaoVar = 0
        for (v in 1 : length(prodvars)){
          if(v %% 2 == 0){next}
          temp = sum((colheitas[[h]][p,v]))
          producaoVar =  producaoVar + temp
        }
        producaoPhase = 0
        chunk = 100/nPhases
        temp2 = producaoVar*(100-(chunk*p-1))/100
        producaoPhase =  producaoPhase + temp2
      }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
  
  # Área 6: o peso da produção cresce com uma ponderação dos valores das variáveis pares:
  # Prod = 0,2*X11 + 0,4* X12 + 0,6*X13 + 0,8*X14 + 1*X15
  else if (areatype == 6) {
    for(h in 1:harvests) {
      for(p in 1:nPhases){
        producaoVar = 0
        for (v in 1 : length(prodvars)){
          if(v %% 2 != 0){next}
          temp = sum((colheitas[[h]][p,v]))
          producaoVar =  producaoVar + temp
        }
        producaoPhase = 0
        chunk = 100/nPhases
        temp2 = producaoVar*(100-(chunk*p-1))/100
        producaoPhase =  producaoPhase + temp2
      }
      colheitas[[h]][,length(prodvars)+1] =  producaoPhase
    }
  }
}#fim else
       

  return(colheitas)
}
```

#### 

#### criaDataFrames

```{r}
# A entrada das funções do pacote bnlearn são dataframes, portanto esta função
# cria os dataframes apartir das listas com os dados gerados nas funções abaixo

criaDataFrames <- function (dados){
  fase <- list()
  area <- list()
  for(k in 1:length(dados)){
    for(j in 1:length(dados[[1]][[1]][,1])){
      area_phase <- matrix(0, nrow=length(dados[[1]]),ncol=length(dados[[1]][[1]][1,]))
      for(i in 1:length(dados[[1]])){
        area_phase[i,] <- dados[[1]][[i]][j,]
      }
      fase[[j]] <- data.frame(area_phase)
      colnames(fase[[j]]) <- colnames(dados[[1]][[1]])
      rownames(fase[[j]]) <- rownames(fase[[j]])
      }
    area[[k]] <- fase
    }
  return(area)
}
```

#### 

#### f_minmax

```{r}
# faz a normalização dos dados
f_minmax <- function(x){
  return((x - min(x))/(max(x)-min(x)))
}

```

#### 

#### def_classes

```{r}
# função para dividir df em classes proporcional à amplitude de valores 

def_classes <- function(n_classes, df_nome){
  val_max <- max(df_nome, na.rm = TRUE)
  val_min <- min(df_nome, na.rm = TRUE)
	amp_total <- val_max - val_min
	amp_classe <- amp_total / n_classes
	classes <- vector()
	classes <- val_min + amp_classe
	for (i in 1:(n_classes -1)) { 
		classes[i+1] <- classes[i] + amp_classe
	}
	nome <- deparse(substitute(df_nome))
	message(nome, " - Classes")	
	return(classes)
}
```

#### 

#### classficator

```{r}

# substitui valores pelo nome da classe a qual o valor pertence 
classficator <- function(input, varclass, names_class) {
  temp = list()
  
  temp[[1]] <- (input <= varclass[1])
  for(i in 2 : length(varclass)){
    temp[[i]] <- (input <= varclass[i] & input > varclass[i-1])
  }
  
  for(i in 1 : length(varclass)){
    input <- replace(input, temp[[i]], names_class[i])
  }
  
  return(input)
}
```

#### 

#### CriaRedes

```{r}
### Cria redes pra todas as fases fenológicas da área
CriaRedes <- function(area_fases){
  
  dagsf <- list()
  class_names <- c(1, 2, 3, 4)
  
  for(fase in 1:length(area_fases[[1]])){
    for(var in 1:dim(area_fases[[1]][[fase]])[2]){
      class <- def_classes(length(class_names),area_fases[[1]][[fase]][var])
      area_fases[[1]][[fase]][var] <- classficator(area_fases[[1]][[fase]][var], class, class_names)
    }
  }
# até aqui beleza... a parte de baixo que eu não sei como fazer...
  

  for(fase in 1:length(area_fases[[1]])){
    df_teste <- area_fases[[1]][[fase]][dim(area_fases[[1]][[fase]])[1],]
    df_treino <- area_fases[[1]][[fase]][1:dim(area_fases[[1]][[fase]])[1]-1,]
    dagsf[[fase]] <- hc(df_treino)
  }
    print(dagsf)
    return(dagsf)
    
## nova proposta:
    
# identificando o tipo de área gerada pra criar a rede correspondente
if(substr(names(areas_teste[2]),13,13) == 1){
  print("tipo 2")
    #area tipo 1: 
    # o peso de produção varia linearmente com os valores de todas as variáveis
    # nas duas primeiras fases fenológicas
    #Prod = (X11 + X12 + X21 + X22 + X31 + X32)

whitelist = data.frame(from = c("variavel_1", "variavel_2", "variavel_3"), to = c("colheita", "colheita", "colheita"))

blacklist = data.frame(from = c("variavel_1","variavel_1",
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
#Criando DAG manualmente
  manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
  # validaRede()
   
  
  
}else  if(substr(names(areas_treino[1]),13,13) == 2){
  print("tipo 2")
  
  whitelist = data.frame(from = c("variavel_1"), to = c("colheita"))

  blacklist = data.frame(from = c("variavel_1","variavel_1", 
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
   manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
  # validaRede()
   
}else  if(substr(names(areas_treino[1]),13,13) == 3){
  print("tipo 3")
    
  whitelist = data.frame(from = c("variavel_3"), to = c("colheita"))

  blacklist = data.frame(from = c("variavel_1","variavel_1", 
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
  
  manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
  # validaRede()
   
}else  if(substr(names(areas_treino[1]),13,13) == 4){
  print("tipo 4")
  
  whitelist = data.frame(from = c("variavel_1", "variavel_3"),
                         to = c("colheita", "colheita"))

  blacklist = data.frame(from = c("variavel_1","variavel_1",
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
   manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
  # validaRede()
   
}else  if(substr(names(areas_treino[1]),13,13) == 5){
  print("tipo 5")
  
  whitelist = data.frame(from = c("variavel_2"), 
                         to = c("colheita"))
  
  blacklist = data.frame(from = c("variavel_1","variavel_1",
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
  manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
  # validaRede()
   
}else  if(substr(names(areas_treino[1]),13,13) == 6){
  print("tipo 6")
  whitelist = data.frame(from = c("variavel_1"),
                         to = c("colheita"))

  blacklist = data.frame(from = c("variavel_1","variavel_1",
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3" #from col
                              ))
   manual_dag = empty.graph(nodes =  c("variavel_1", "variavel_2", "variavel_3", "colheita"))
  arc_set = as.matrix(whitelist)
  arcs(manual_dag) = arc_set
  plot(manual_dag)

  hc_dag_2 <-hc(areas_teste[[1]][[1]])
  
  bn1 = bn.fit(manual_dag, areas_teste[[1]][[1]])
  bn2 = bn.fit(hc_dag_2, areas_teste[[1]][[1]])
  
   #validaRede()
   
}


#AINDA NÃO SEI COMO GERAR AS REDES DE FORMA AUTOMÁTICA SATISFATORIAMENTE, 
# PORÉM, DEPOIS DE GERADAS VOU PRECISAR USAR ELA DE MODO AUTOMÁTICO TBM
# E PRA ISSO EU NÃO FAÇO A MENOR INDEIA DE COMO FAZER
}

```

#### testes

```{r}
iniciaTeste <- function(){
  file_path = "/home/gui/TCC/R/meu_pacote/teste1.csv"
  nHarvests = 33
  nphases = 5
  nAreas = 2
  nVars = 3
  class_names <- c("B", "MB", "M", "MA", "A")
# listas para armazenar os dados por área
  areas_list  = list()
  areas_list  = BuildSimulationData(nHarvests, nphases)

#para cada área, cria uma lista de dataframes
#cada dataframe tem os dados de uma fase fenológica
  for(area in 1:length(areas_list)){
    areas_list[area] = criaDataFrames(areas_list[area])
  }
  
    #TENTATIVA de discretizar as variáveis com a função discretize do pacote, 
    # mas dá erro quando uma variável não varia ao longo das colheitas... 
  
    for(area in  1:length(areas_list)){#para cada área
      for(fase in 1:length(areas_list[[1]])){#para cada fase da área
        areas_list[[area]][[fase]] <- discretize(areas_list[[area]][[fase]], breaks = 5)
        for(var in 1:dim(areas_list[[1]][[fase]])[2]){#para cada variável da área/fase
          levels(areas_list[[area]][[fase]][,var]) <- class_names
        }
      }
    }  
        # Versão anterior com as funções criadas pra discretizar as variáveis...
        #mas daí descobri que tem uma função no pacote bnlear que faz isso
        #        class = def_classes(length(class_names), areas_list[[area]][[fase]][var])
        #       areas_list[[area]][[fase]][var] = classficator(areas_list[[area]][[fase]][var], class, class_names)
        #       areas_list[[area]][[fase]][,var] = factor(areas_list[[area]][[fase]][,var], class_names)
        #     }
        #   }
        # }
  
  return(areas_list)
}
```

```{r}
validaRede <- function(areas_teste, bn){
  
  #função para testar a capacidade de inferência da REDE
  #por enquanto apenas printa os testes
  #preciso aplicar métodos de verdade de validação tipo matriz de confusão etc
  #tentei e não consegui especificar o DF como parâmetro mas não consigo
  
  for(colheita in 1 : length(areas_teste[[1]][[1]][,1])){
    cat("colheita", colheita, ":\n") 
    for (class in 1: length(class_names)){ 
      temp = class_names[class] 
      cat("Classe:", temp, ":") 
      print(cpquery(bn, 
                  event = (colheita ==temp),
                  evidence = ((variavel_1 == areas_teste[[6]][[5]]['variavel_1'][colheita,1]) &
                                (variavel_2 == areas_teste[[6]][[5]]['variavel_2'][colheita,1]) & 
                                (variavel_3 == areas_teste[[6]][[5]]['variavel_3'][colheita,1])))) 
  }
}
  }
```

```{r metricas}

# trecho copiado do repositório https://github.com/KaikeWesleyReis/bnlearn-multivar-prediction-metrics
# VER COMO CITAR NO TCC, CASO MANTIDO

# FUNCTION - Multi Variable Discrete prediction
bnMultiVarPrediction <- function(bnFit, trainSet, testSet, to_predict, to_evidence, nSamples = NULL, calcFunction = NULL){
  # Probabilities predictions for each sample
  pred_list_prob = list()
  
  # Dominant output predicted for each sample
  pred_list_domi = list()
  
  # Auxiliar variables
  N <- nrow(testSet) # Number of samples
  np <- length(to_predict) # Number of variables to predict
  
  # Loop into all possible variables to Generate our output format
  for(j in to_predict){
    # TARGET LEVELS (CATEGORIES)
    tv_lvls =  levels(trainSet[,j])
    # DATAFRAME - PROBABILITIES PREDICTIONS
    prob_pred <- setNames(data.frame(matrix(ncol = length(tv_lvls), nrow = N)), tv_lvls)
    # DATAFRAME - DOMINANT OUTCOME
    domi_pred <- setNames(data.frame(matrix(ncol = 1, nrow = N)), j)
    # LISTS - APPEND
    pred_list_prob[[j]] = prob_pred
    pred_list_domi[[j]] = domi_pred
  }
  
  # Multi Var Prediction :: PREDICT FUNCTION
  if(calcFunction == 'predict' || is.null(calcFunction)){
    for (i in 1:N){ 
      # Prediction process
      for(j in to_predict){
        predicted = predict(bnFit, j, testSet[i, names(testSet) %in% to_evidence], prob = TRUE, method = 'bayes-lw')
        ## TAKING IMPORTANT RESULTS
        dominant = as.character(predicted)
        probs = attr(predicted,'prob')
        ## DOMINANT OUTPUT
        pred_list_domi[[j]][i,j] = dominant
        ## PROBABILITY OUTPUT
        tv_lvls = colnames(pred_list_prob[[j]])
        ## LOOP INTO ALL LEVELS TO SAVE YOUR PROBABILITY
        for(k in tv_lvls){ 
          pred_list_prob[[j]][i,k] = as.numeric(probs[k,])
        }
      }
    }    
  }
  
  # Multi Var Prediction :: CPDIST FUNCTION
  else if(calcFunction == 'cpdist'){
    # nSamples Verification
    if(is.null(nSamples) || typeof(nSamples) != 'double'){ # Default value for N samples is 10.000 samples generated
      nSamples <- 10000
    }
    # Prediction process
    for (i in 1:N){
      predicted = cpdist(fitted = bnFit, nodes = to_predict, evidence = as.list(test[i, names(test) %in% to_evidence]), n = nSamples, method = 'lw')
      for(j in to_predict){ # Loop into all variables to be predicted
        # PROBABILITY OUTPUT
        probs = table(predicted[,j])/nrow(predicted)
        # DOMINANT OUTPUT
        pred_list_domi[[j]][i,j] = names(which.max(probs))
        # KEEP PROB VALUES
        tv_lvls = colnames(pred_list_prob[[j]])
        for(k in tv_lvls){ # Loop into all lvls to save the probability
          pred_list_prob[[j]][i,k] = as.numeric(probs[k])
        }
      }
    }    
  }
  
  # Turn dominant output in factors - help metrics CM
  for(j in to_predict){
    #levels(pred_list_domi[[j]]) <- levels(trainSet[,j])
    pred_list_domi[[j]] <- factor(x = unlist(pred_list_domi[[j]], use.names = F), levels = levels(trainSet[,j]))
  }
  # Returning
  ret_list <- list("probList" = pred_list_prob, "dominantList" = pred_list_domi)
  return(ret_list)
}

# FUNCTION - Metrics :: Confusion Matrix by OVA and Scoring Rules
bnMetricsMultiVarPrediction <- function(reference, prediction, predProbList){
  # AUXILIAR VARs
  np <- length(names(prediction))
  to_predict <- names(prediction)
  N <- nrow(reference)
  
  # METRICS DATASET CREATION
  metricsType <- c('accuracy','accuracyOVA','sensibilityOVA','specificityOVA','precisionOVA','f1-scoreOVA','mccOVA','sphericalPayoff','brierLoss','logLoss')
  metrics <- setNames(data.frame(matrix(ncol = length(metricsType), nrow = length(to_predict)), row.names = to_predict), metricsType)
  
  
  # CONFUSION MATRIX
  cm_list <- setNames(vector(mode = "list", length = np), to_predict)
  for(j in to_predict){
    cm_list[[j]] <- table(prediction[[j]], reference[[j]])
    
    #### PRINT - CM
    #cat(paste('CONFUSION MATRIX - ',j,' Variable:\n'))
    #print(cm_list[[j]])
    #cat('\n')
    
  }
  
  # ONE VS ALL (OVA) CALCULATION
  ova_list <- setNames(vector(mode = "list", length = np), to_predict)
  for(j in to_predict){
    # OVA INIT
    lvls_var = colnames(cm_list[[j]])
    ova_list[[j]] <- setNames(vector(mode = "list", length = length(lvls_var)), lvls_var)
    
    ### PRINT
    #cat(paste('ONE VS ALL - ',j,'Variable:\n\n'))
    
    # LOOP TO DEVELOP EACH v CLASS VS ALL MATRIX FOR A j VARIABLE
    for(v in lvls_var){
      ## MATRIX CREATION
      ova_lvl <- matrix(0,nrow = 2, ncol = 2)
      row.names(ova_lvl) = c(v,'All')
      colnames(ova_lvl) = c(v,'All')
      ## RENAME cm_list FROM OUR j VARIABLE TO BETTER CODE READING
      cm = cm_list[[j]]
      ## AUXILIAR VARIABLES
      rs = rowSums(cm) 
      cs = colSums(cm)
      n = sum(cm)
      
      ## TAKING BINARIES VALUES FROM A BINARY C.M.
      tp = cm[v,v]
      fn = rs[v] - cm[v,v]
      fp = cs[v] - cm[v,v]
      tn = n - rs[v] - cs[v] + cm[v,v]
      
      ## INSERT THE VALUES IN OVA C.M.
      ova_lvl[v,v] <- tp
      ova_lvl[v,'All'] <- fn
      ova_lvl['All',v] <- fp
      ova_lvl['All','All'] <- tn
      
      ## SAVE OVA INSIDE THE LIST FOR THAT j TARGET
      ova_list[[j]][[v]] <- ova_lvl
      
      #### PRINT - OVA
      #print(ova_list[[j]][[v]])
      #cat('\n')
      
    }
  }
  
  # CONFUSION MATRIX METRICS - ONE VS ALL :: SEN, SPECIFICITY, RECALL, ACCURACY, F1-SCORE, MCC, ACCURACY OVA
  for(j in to_predict){
    cm <- cm_list[[j]]
    # ACCURACY
    cmACC <- 100*(sum(diag(cm))/sum(cm))
    
    ### SAVE INTO DATAFRAME RESULT
    metrics[j,'accuracy'] <- round(cmACC,2)
    
    ### PRINT - ACCURACY MULTI-CLASS
    cat(paste('#### CONFUSION MATRIX METRICS - ',j,' Variable ####\n'))
    cat(paste('+ ACCURACY: ', round(cmACC,2),'\n'))
    
    ## OVA :: AUXILIAR VARIABLES - REPRESENT VECTOR FOR EACH v LEVELS VS ALL
    acc = c()
    sen = c()
    spe = c()
    pre = c()
    f1s = c()
    mcc = c()
    ## OVA :: AUXILIAR VARs
    lvls <- names(ova_list[[j]])
    len_lvls <- length(lvls)
    ## OVA :: LOOP INTO ALL l LEVELS FROM j VARIABLE TO CALCULATE METRICS FOR EACH LEVEL
    for(l in lvls){
      ## AUXILIAR VARIABLE TO IMPROVE CODE READING
      ovaCM <- ova_list[[j]][[l]]
      ## GETTING BINARY TERMS FROM ovaCM
      tp = ovaCM[l,l]
      fn = ovaCM[l,'All']
      fp = ovaCM['All',l]
      tn = ovaCM['All','All']
      
      ## CALCULATE METRICS FOR THAT LVL AND SUM WITH PREVIOUS PART 1
      acc = c(acc,((tp+tn)/(tp+tn+fp+fn)))
      sen = c(sen,(tp/(tp+fn)))
      spe = c(spe,(tn/(tn+fp)))
      pre = c(pre,(tp/(tp+fp)))
      
      # AUXILIAR CALCULATION FOR MCC AND F1S
      sen_unq = tp/(tp+fn)
      pre_unq = tp/(tp+fp)
      f1s_unq = 2*((sen_unq*pre_unq)/(sen_unq+pre_unq))
      mcc_num = (tp*tn) - (fp*fn)
      mcc_den = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)
      
      ## CALCULATE METRICS FOR THAT LVL AND SUM WITH PREVIOUS PART 2
      f1s = c(f1s,f1s_unq)
      mcc = c(mcc,(mcc_num/sqrt(mcc_den)))
    }
    ## OVA :: RESULT FOR EACH j VARIABLE BASED ON A MEAN FROM ALL OVA MATRIX FROM THAT VARIABLE i.e. ALL LEVELS OVA MATRIX
    cmACC_ova <- 100*(sum(acc, na.rm = T)/len_lvls)
    cmSEN_ova <- 100*(sum(sen, na.rm = T)/len_lvls)
    cmSPE_ova <- 100*(sum(spe, na.rm = T)/len_lvls)
    cmPRE_ova <- 100*(sum(pre, na.rm = T)/len_lvls)
    cmF1S_ova <- 100*(sum(f1s, na.rm = T)/len_lvls)
    cmMCC_ova <- 100*(sum(mcc, na.rm = T)/len_lvls)
    
    ### PRINT - OVA METRICS
    cat(paste('+ ACCURACY OVA: ', round(cmACC_ova,2),'\n'))
    cat(paste('+ SENSIBILITY OVA: ', round(cmSEN_ova,2),'\n'))
    cat(paste('+ SPECIFICITY OVA: ', round(cmSPE_ova,2),'\n'))
    cat(paste('+ PRECISION OVA: ', round(cmPRE_ova,2),'\n'))
    cat(paste('+ F1-SCORE OVA: ', round(cmF1S_ova,2),'\n'))
    cat(paste('+ MCC OVA: ', round(cmMCC_ova,2),'\n'))
    
    ### SAVE INTO DATAFRAME RESULT
    metrics[j,'accuracyOVA'] <- round(cmACC_ova,2)
    metrics[j,'sensibilityOVA'] <- round(cmSEN_ova,2)
    metrics[j,'specificityOVA'] <- round(cmSPE_ova,2)
    metrics[j,'precisionOVA'] <- round(cmPRE_ova,2)
    metrics[j,'f1-scoreOVA'] <- round(cmF1S_ova,2)
    metrics[j,'mccOVA'] <- round(cmMCC_ova,2)
    
  }
  
  # SCORING RULES CALC
  for(j in to_predict){
    ## AUXILIAR VARIABLES
    aux_prob <- predProbList[[j]]
    cor_test <- reference[j]
    states <- colnames(aux_prob)
    
    ## TERMS FOR THE FORMULAS :: init
    pc = 0
    pj_2 = 0
    sum_pj = 0
    
    ## TERMS FOR :: SPHERICAL PAYOFF
    smp_spher_payoff = 0
    srSP = 0
    
    ## TERMS FOR :: BRIER LOSS
    smp_brier_loss = 0
    srBL = 0
    
    ## TERMS FOR :: LOG LOSS
    smp_log_loss = 0
    srLL = 0
    
    ## LOOP THROUGH ALL THE N SAMPLES PREDICTED
    for(i in 1:N){
      correct_state = cor_test[i,]
      ## TERMS CALCULATION
      pc = aux_prob[i,correct_state]
      sum_pj = 0
      for(s in states){
        pj_2 = aux_prob[i,s] * aux_prob[i,s]
        sum_pj = sum_pj + pj_2
      }
      
      ## SCORING RULE CALC FOR EACH SAMPLE - SP
      smp_spher_payoff = pc/sqrt(sum_pj)
      srSP = srSP + smp_spher_payoff
      
      ## SCORING RULE CALC FOR EACH SAMPLE - BL 
      #smp_brier_loss = 1-(2*pc+sum_pj)
      smp_brier_loss = 2*pc-sum_pj
      srBL = srBL + smp_brier_loss   
      
      ## SCORING RULE CALC FOR EACH SAMPLE - LL
      smp_log_loss = (-log(pc))
      srLL = srLL + smp_log_loss
    }
    
    ## RESULT - SPHERICAL PAYOFF (MOAC)
    srSP = srSP/N
    srBL = srBL/N
    srLL = srLL/N
    
    ### PRINT - SCORING RULES
    cat(paste('#### SCORING RULES METRICS - ',j,' Variable ####\n'))
    cat(paste('+ SPHERICAL PAYOFF: ', round(srSP,2),'\n'))
    cat(paste('+ BRIER LOSS: ', round(srBL,2),'\n'))
    cat(paste('+ LOG LOSS: ', round(srLL,2),'\n'))
    
    ### SAVE INTO DATAFRAME RESULT
    metrics[j,'sphericalPayoff'] <- round(srSP,2)
    metrics[j,'brierLoss'] <- round(srBL,2)
    metrics[j,'logLoss'] <- round(srLL,2)
  }
  
  # RETURN
  ret_list <- list('cmList' = cm_list, 'ovaList' = ova_list, 'eval' = metrics)
  
}

```

```{r TESTE} 

areas_treino <- iniciaTeste() 
areas_teste <- iniciaTeste()


# RASCUNHO:
# DAQUI pra baixo sõa testes das funções do pacote.
summary(areas_treino[[1]][[4]])

# aqui abaixo eu testo alguns algorítomos de aprendizado de estrutura de 
# redes bayesianas, mas não evoluiu muito por conta dos problemas 
# que te reportei mais acima

## esse trecho abaixo DEVERIA ir pra função CriaRedes() a IDEIA da função
## CriaRedes seria gerar várias redes por vários algorítmos de aprendizados de
## estrutura e selecionar o com o melhor score 
##  (a função score() parece promissora pra isso), mas não estudei ela o suficiente


## DE QQ FORMA abaixo gero uma rede pelo algorírmo Hill climbing, pra área 1
# e teste ela 

#### Hill climbing ###

  whitelist = data.frame(from = c("variavel_1", "variavel_2", "variavel_3"), to = c("colheita", "colheita", "colheita"))
  blacklist = data.frame(from = c("variavel_1","variavel_1",
                                "variavel_2", "variavel_2",
                                "variavel_3", "variavel_3",
                                "colheita",  "colheita",  "colheita" ), 
                       to = c("variavel_2", "variavel_3", #from v1 
                              "variavel_1", "variavel_3", #from v2
                              "variavel_1", "variavel_2", #from v3
                              "variavel_1", "variavel_2", "variavel_3")) #from col
  
  hc_dag <-hc(areas_treino[[1]][[4]], debug = FALSE, whitelist = whitelist, blacklist = blacklist)
  plot(hc_dag)
  hc_dag2 <-hc(areas_treino[[1]][[4]], debug = FALSE)
  plot(hc_dag2) 
  
  
  score(hc_dag, data = areas_treino[[1]][[4]], type = "bic")
  score(hc_dag2, data = areas_treino[[1]][[4]], type = "bic")
  
  arc.strength(hc_dag, data = areas_treino[[1]][[4]], criterion = "bic")
  arc.strength(hc_dag2, data = areas_treino[[1]][[4]], criterion = "bic")

  hc_dag_fitted = bn.fit(hc_dag, areas_treino[[1]][[4]])
  hc_dag2_fitted = bn.fit(hc_dag2, areas_treino[[1]][[4]])
  
  #areas_teste_disc
  #bn_hc_dag[[4]]
  
  #Esse trecho das próximas linhas DEVERIAM estar na função 'validaRede()'
  cpquery(hc_dag_fitted, 
                  event = (colheita == "A"),
                  evidence = ((variavel_1 == "B") &
                                (variavel_2 == "A") & 
                                (variavel_3 == "A")))
  
  
### RASCUNHO
  # TEM POTENCIAL
  
# Define Train and Test
  test <- areas_teste[[1]][[4]]
  train <- areas_treino[[1]][[4]]
  
# Create and fit model
  #hc_dag_fitted = bn.fit(hc_dag, areas_treino[[1]][[4]])
  #hc_dag2_fitted = bn.fit(hc_dag2, areas_treino[[1]][[4]])
# Plot model
  #plot(hc(train))
  
# Define Target variables (Variables to be predicted)
  pred <-'colheita'
# Evidence variables (Variables that you will give information to the BN to do the prediction)
  evid <- names(train)[!names(train) %in% pred]

# Multi var Prediction
results <- bnMultiVarPrediction(bnFit = hc_dag_fitted, 
                                trainSet = train,
                                testSet = test,
                                to_predict = pred,
                                to_evidence = evid, 
                                calcFunction = 'predict')
results

# Metrics Evaluation
metrics <- bnMetricsMultiVarPrediction(reference = test[pred],
                                       prediction = results$dominantList,
                                       predProbList = results$probList)
  
  

```